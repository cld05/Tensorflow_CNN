import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from sklearn.metrics import confusion_matrix
import time
from datetime import timedelta
import math

# Definition of the properties of the CNN layers
# Layer 1
filter_size1 = 5  # filter 5x5 pixels
num_filters1 = 16  # number of filters in the first layer

# Layer 2
filter_size2 = 5  # filter size 5x5 pixels
num_filters2 = 36  # number of filters in the second layer

# Final fully-connected layer
fc_size = 128

# Define the size of the stride operation
stride = 1

# Data download from MNIST dataset
from tensorflow.examples.tutorials.mnist import input_data
data = input_data.read_data_sets('data/MNIST/', one_hot=True)

# The dataset above gives one hot encoded labels
# Here we create labels associated to class name
data.test.cls = np.argmax(data.test.labels, axis=1)

# Definition of the size of our data
img_size = 28  # images are 28x28 pixles (1 channel since balck and white)
img_flat_size = img_size * img_size  # Size of flattened image
# tuple to be used when reshaping flattened image in 2-dimensional array
img_shape = (img_size, img_size)
num_channels = 1  # black and white images have only 1 channel
num_cls = 10  # we will calssify handwritten digits from 0 to 9

# Definition of funcitons to create random weights and biases


def new_weights(shape):
    return tf.Variable(tf.truncared_normal(shape, stddev=0.05))


def new_biases(length):
    return tf.Variable(tf.constant(0.05, shape=[length]))

# This funciton is used to create new convolutional layer
# Each convolutional layer must take into account the output of the previous one


def new_conv_layer(input, num_input_channels, filter_size, num_filters, use_pooling=True):

    # Shape of the filter-weights
    # This shape is coherent with what imposed by tensorflow API
    shape = [filter_size, filter_size, num_input_channels, num_filters]

    # The weights for the filter are created here using the function
    # defined above and the variable 'shape' just defined
    weights = new_weights(shape=shape)

    # The biases for the filters are created using the helper funciton
    # created above and the variable 'num_filters'
    biases = new_biases(length=num_filters)

    # We can now create the convolutional layer using the variables defined above
    layer = tf.nn.conv2d(input=input,
                         filter=weights,
                         strides=[1, stride, stride, 1],
                         padding='SAME')
    # Adding the biases to the filters of the layer
    layer += biases

    # if we have chose to use pooling we apply it
    if use_pooling:
        layer = tf.nn.max_pool(value=layer,
                               ksize=[1, 2, 2, 1],
                               strides=[1, stride, stride, 1],
                               pooling='SAME')
    layer = tf.nn.relu(layer)

    return layer, weights

# The output of the convolutional layers is 4-dimensional
# we need to reduce it to a 2-dimensional one


def flatten_layer(layer):
    layer_shape = layer.get_shape()
    num_features = np.array(layer_shape, dtype=int).prod()
    layer_flat = tf.reshape(layer, [-1, num_features])

    return layer_flat, num_features


def new_fc_layer(input,
                 num_inputs,
                 num_outputs,
                 use_relu=True):
    weights = new_weights(shape=[num_inputs, num_outputs])
    biases = new_biases(length=num_outputs)

    layer = tf.matmul(input, weights) + biases

    if use_relu:
        layer = tf.nn.relu(layer)

    return layer


# Create place holder variables
# variable for the fully connected layer
x = tf.placeholder(tf.float32, shape=[None, img_flat_size], name='x')
# variable for the convolutional layers
x_img = tf.reshape(x, [-1, img_size, img_size, num_channels])
# variable for true values of the MNIST data
y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')
y_true_cls = tf.arg_max(y_true, dimension=1)

# We can now create the convolutional layers
conv1 = new_conv_layer(input=x_img,
                       num_input_channels=num_channels,
                       filter_size=filter_size1,
                       num_filters=num_filters1,
                       use_pooling=True)

conv2 = new_conv_layer(input=conv1,
                       num_input_channels=num_channels,
                       filter_size=filter_size2,
                       num_filters=num_filters2,
                       use_pooling=True)
